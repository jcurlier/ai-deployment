{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earning Prediction using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:09.589190Z",
     "start_time": "2018-10-24T05:16:09.586634Z"
    }
   },
   "outputs": [],
   "source": [
    "RUN_NAME = 'tensorflow-run-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "- https://pandas.pydata.org/\n",
    "- http://scikit-learn.org/stable/\n",
    "- https://www.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:11.465071Z",
     "start_time": "2018-10-24T05:16:09.591463Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:11.472731Z",
     "start_time": "2018-10-24T05:16:11.468566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Turn off TensorFlow warning messages in program output\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "LOGDIR = Path('output/logs/{}'.format(RUN_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:11.522243Z",
     "start_time": "2018-10-24T05:16:11.475535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic_rating</th>\n",
       "      <th>is_action</th>\n",
       "      <th>is_exclusive_to_us</th>\n",
       "      <th>is_portable</th>\n",
       "      <th>is_role_playing</th>\n",
       "      <th>is_sequel</th>\n",
       "      <th>is_sports</th>\n",
       "      <th>suitable_for_kids</th>\n",
       "      <th>total_earnings</th>\n",
       "      <th>unit_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132717.0</td>\n",
       "      <td>59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83407.0</td>\n",
       "      <td>49.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62423.0</td>\n",
       "      <td>49.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69889.0</td>\n",
       "      <td>39.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161382.0</td>\n",
       "      <td>59.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   critic_rating  is_action  is_exclusive_to_us  is_portable  is_role_playing  \\\n",
       "0            3.5        1.0                 0.0          1.0              0.0   \n",
       "1            4.5        0.0                 0.0          0.0              0.0   \n",
       "2            3.0        0.0                 0.0          0.0              0.0   \n",
       "3            4.5        1.0                 0.0          0.0              0.0   \n",
       "4            4.0        1.0                 0.0          1.0              0.0   \n",
       "\n",
       "   is_sequel  is_sports  suitable_for_kids  total_earnings  unit_price  \n",
       "0        1.0        0.0                0.0        132717.0       59.99  \n",
       "1        1.0        1.0                0.0         83407.0       49.99  \n",
       "2        1.0        1.0                0.0         62423.0       49.99  \n",
       "3        0.0        0.0                1.0         69889.0       39.99  \n",
       "4        1.0        0.0                1.0        161382.0       59.99  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data set from CSV file\n",
    "training_data_df = pd.read_csv(\"data/sales_data_training.csv\", dtype=float)\n",
    "training_data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:11.531777Z",
     "start_time": "2018-10-24T05:16:11.525941Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pull out columns for X (data to train with) and Y (value to predict)\n",
    "X_training = training_data_df.drop('total_earnings', axis=1).values\n",
    "Y_training = training_data_df[['total_earnings']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:11.557142Z",
     "start_time": "2018-10-24T05:16:11.534168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic_rating</th>\n",
       "      <th>is_action</th>\n",
       "      <th>is_exclusive_to_us</th>\n",
       "      <th>is_portable</th>\n",
       "      <th>is_role_playing</th>\n",
       "      <th>is_sequel</th>\n",
       "      <th>is_sports</th>\n",
       "      <th>suitable_for_kids</th>\n",
       "      <th>total_earnings</th>\n",
       "      <th>unit_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>247537.0</td>\n",
       "      <td>59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73960.0</td>\n",
       "      <td>59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82671.0</td>\n",
       "      <td>59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137456.0</td>\n",
       "      <td>39.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89639.0</td>\n",
       "      <td>59.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   critic_rating  is_action  is_exclusive_to_us  is_portable  is_role_playing  \\\n",
       "0            3.5        1.0                 1.0          1.0              0.0   \n",
       "1            2.5        0.0                 0.0          0.0              1.0   \n",
       "2            3.5        0.0                 0.0          0.0              0.0   \n",
       "3            4.0        1.0                 1.0          0.0              0.0   \n",
       "4            2.0        1.0                 0.0          1.0              0.0   \n",
       "\n",
       "   is_sequel  is_sports  suitable_for_kids  total_earnings  unit_price  \n",
       "0        1.0        0.0                1.0        247537.0       59.99  \n",
       "1        1.0        0.0                0.0         73960.0       59.99  \n",
       "2        1.0        1.0                0.0         82671.0       59.99  \n",
       "3        1.0        0.0                0.0        137456.0       39.99  \n",
       "4        1.0        0.0                0.0         89639.0       59.99  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load testing data set from CSV file\n",
    "test_data_df = pd.read_csv(\"data/sales_data_test.csv\", dtype=float)\n",
    "test_data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:11.564161Z",
     "start_time": "2018-10-24T05:16:11.559219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pull out columns for X (data to train with) and Y (value to predict)\n",
    "X_testing = test_data_df.drop('total_earnings', axis=1).values\n",
    "Y_testing = test_data_df[['total_earnings']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:11.571840Z",
     "start_time": "2018-10-24T05:16:11.566422Z"
    }
   },
   "outputs": [],
   "source": [
    "# All data needs to be scaled to a small range like 0 to 1 for the neural\n",
    "# network to work well. Create scalers for the inputs and outputs.\n",
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale both the training inputs and outputs\n",
    "X_scaled_training = X_scaler.fit_transform(X_training)\n",
    "Y_scaled_training = Y_scaler.fit_transform(Y_training)\n",
    "\n",
    "# It's very important that the training and test data are scaled with the same scaler.\n",
    "X_scaled_testing = X_scaler.transform(X_testing)\n",
    "Y_scaled_testing = Y_scaler.transform(Y_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:11.578135Z",
     "start_time": "2018-10-24T05:16:11.574270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y values were scaled by multiplying by 0.0000036968 and adding -0.1159\n"
     ]
    }
   ],
   "source": [
    "print(\"Y values were scaled by multiplying by {:.10f} and adding {:.4f}\".format(Y_scaler.scale_[0], Y_scaler.min_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:11.589226Z",
     "start_time": "2018-10-24T05:16:11.583111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 1.  0.  1.  0.  1.  0.  0.  1. ]\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled_training[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:11.597510Z",
     "start_time": "2018-10-24T05:16:11.592095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37471396]\n"
     ]
    }
   ],
   "source": [
    "print(Y_scaled_training[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:11.605793Z",
     "start_time": "2018-10-24T05:16:11.600334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "(400, 9)\n",
      "(400, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Shapes')\n",
    "print(X_scaled_testing.shape)\n",
    "print(Y_scaled_testing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:17.033043Z",
     "start_time": "2018-10-24T05:16:11.613117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "display_step = 5\n",
    "\n",
    "# Define how many inputs and outputs are in our neural network\n",
    "number_of_inputs = 9\n",
    "number_of_outputs = 1\n",
    "\n",
    "# Define how many neurons we want in each layer of our neural network\n",
    "layer_1_nodes = 50\n",
    "layer_2_nodes = 100\n",
    "layer_3_nodes = 50\n",
    "\n",
    "# Section One: Define the layers of the neural network itself\n",
    "\n",
    "# Input Layer\n",
    "with tf.variable_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))\n",
    "\n",
    "# Layer 1\n",
    "with tf.variable_scope('layer_1'):\n",
    "    weights = tf.get_variable(\"weights1\", shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
    "\n",
    "# Layer 2\n",
    "with tf.variable_scope('layer_2'):\n",
    "    weights = tf.get_variable(\"weights2\", shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n",
    "\n",
    "# Layer 3\n",
    "with tf.variable_scope('layer_3'):\n",
    "    weights = tf.get_variable(\"weights3\", shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
    "    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n",
    "\n",
    "# Output Layer\n",
    "with tf.variable_scope('output'):\n",
    "    weights = tf.get_variable(\"weights4\", shape=[layer_3_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "    prediction = tf.matmul(layer_3_output, weights) + biases\n",
    "\n",
    "# Section Two: Define the cost function of the neural network that will measure prediction accuracy during training\n",
    "\n",
    "with tf.variable_scope('cost'):\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "    cost = tf.reduce_mean(tf.squared_difference(prediction, Y))\n",
    "\n",
    "# Section Three: Define the optimizer function that will be run to optimize the neural network\n",
    "\n",
    "with tf.variable_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:17.587617Z",
     "start_time": "2018-10-24T05:16:17.035491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Training Cost: 0.02705908752977848  Testing Cost: 0.028945259749889374\n",
      "Epoch: 5 - Training Cost: 0.011612320318818092  Testing Cost: 0.01396175380796194\n",
      "Epoch: 10 - Training Cost: 0.00831885077059269  Testing Cost: 0.009200850501656532\n",
      "Epoch: 15 - Training Cost: 0.005509235430508852  Testing Cost: 0.0064634038135409355\n",
      "Epoch: 20 - Training Cost: 0.003075777553021908  Testing Cost: 0.0034968226682394743\n",
      "Epoch: 25 - Training Cost: 0.0023623700253665447  Testing Cost: 0.0026602190919220448\n",
      "Epoch: 30 - Training Cost: 0.0020820503123104572  Testing Cost: 0.002409636275842786\n",
      "Epoch: 35 - Training Cost: 0.001537898788228631  Testing Cost: 0.0016911652637645602\n",
      "Epoch: 40 - Training Cost: 0.0011657190043479204  Testing Cost: 0.0012751355534419417\n",
      "Epoch: 45 - Training Cost: 0.0009357126546092331  Testing Cost: 0.0009707102435640991\n",
      "Epoch: 50 - Training Cost: 0.0007372793043032289  Testing Cost: 0.0008163382881321013\n",
      "Epoch: 55 - Training Cost: 0.0006156013696454465  Testing Cost: 0.0006816333625465631\n",
      "Epoch: 60 - Training Cost: 0.0005082697607576847  Testing Cost: 0.0005958545953035355\n",
      "Epoch: 65 - Training Cost: 0.0004208143218420446  Testing Cost: 0.0004949910216964781\n",
      "Epoch: 70 - Training Cost: 0.00035044061951339245  Testing Cost: 0.0004348884103819728\n",
      "Epoch: 75 - Training Cost: 0.00029248971259221435  Testing Cost: 0.0003774514771066606\n",
      "Epoch: 80 - Training Cost: 0.00024897194816730917  Testing Cost: 0.000337159086484462\n",
      "Epoch: 85 - Training Cost: 0.0002135981630999595  Testing Cost: 0.0003074543783441186\n",
      "Epoch: 90 - Training Cost: 0.000184401695150882  Testing Cost: 0.0002826465934049338\n",
      "Epoch: 95 - Training Cost: 0.00016043480718508363  Testing Cost: 0.0002619224542286247\n",
      "Training is now complete\n",
      "Final Training cost: 0.00014441552048083395\n",
      "Final Testing cost: 0.00024867153842933476\n"
     ]
    }
   ],
   "source": [
    "# Delete the folder directory\n",
    "if os.path.exists(LOGDIR):\n",
    "    shutil.rmtree(LOGDIR)\n",
    "\n",
    "# Create a summary operation to log the progress of the network\n",
    "with tf.variable_scope('logging'):\n",
    "    tf.summary.scalar('current_cost', cost)\n",
    "    tf.summary.histogram('predicted_value', prediction)\n",
    "    summary = tf.summary.merge_all()\n",
    "\n",
    "# Initialize a session so that we can run TensorFlow operations\n",
    "session = tf.Session()\n",
    "\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "# Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "# Instead, load them from disk:\n",
    "# saver.restore(session, \"models/tf_trained_model.ckpt\")\n",
    "    \n",
    "# Create log file writers to record training progress.\n",
    "# We'll store training and testing log data separately.\n",
    "training_writer = tf.summary.FileWriter('{}/training'.format(LOGDIR), session.graph)\n",
    "testing_writer = tf.summary.FileWriter('{}/testing'.format(LOGDIR), session.graph)\n",
    "\n",
    "# Run the optimizer over and over to train the network.\n",
    "# One epoch is one full run through the training data set.\n",
    "for epoch in range(training_epochs):\n",
    "\n",
    "    # Feed in the training data and do one step of neural network training\n",
    "    session.run(optimizer, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n",
    "\n",
    "    # Every 5 training steps, log our progress\n",
    "    if epoch % 5 == 0:\n",
    "        # Get the current accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "        training_cost, training_summary = session.run([cost, summary], feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n",
    "        testing_cost, testing_summary = session.run([cost, summary], feed_dict={X: X_scaled_testing, Y: Y_scaled_testing})\n",
    "\n",
    "        # Write the current training status to the log files (Which we can view with TensorBoard)\n",
    "        training_writer.add_summary(training_summary, epoch)\n",
    "        testing_writer.add_summary(testing_summary, epoch)\n",
    "\n",
    "        # Print the current training status to the screen\n",
    "        print(\"Epoch: {} - Training Cost: {}  Testing Cost: {}\".format(epoch, training_cost, testing_cost))\n",
    "\n",
    "# save_path = saver.save(session, \"models/tf_trained_model.ckpt\")\n",
    "# print(\"Model saved: {}\".format(save_path))\n",
    "    \n",
    "# Training is now complete!\n",
    "training_writer.close()\n",
    "testing_writer.close()\n",
    "\n",
    "print(\"Training is now complete\")\n",
    "\n",
    "# Get the final accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "final_training_cost = session.run(cost, feed_dict={X: X_scaled_training, Y: Y_scaled_training})\n",
    "final_testing_cost = session.run(cost, feed_dict={X: X_scaled_testing, Y: Y_scaled_testing})\n",
    "\n",
    "print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "print(\"Final Testing cost: {}\".format(final_testing_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:17.797633Z",
     "start_time": "2018-10-24T05:16:17.589958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: models/tf_exported_model/saved_model.pb\n",
      "model saved to models/tf_exported_model\n"
     ]
    }
   ],
   "source": [
    "# Export the model\n",
    "\n",
    "# Delete the existing folder (if there)\n",
    "model_path = Path('models/tf_exported_model')\n",
    "if os.path.exists(model_path):\n",
    "    shutil.rmtree(model_path)\n",
    "    \n",
    "model_builder = tf.saved_model.builder.SavedModelBuilder(\"models/tf_exported_model\")\n",
    "\n",
    "inputs = {\n",
    "    'input': tf.saved_model.utils.build_tensor_info(X)\n",
    "    }\n",
    "outputs = {\n",
    "    'earnings': tf.saved_model.utils.build_tensor_info(prediction)\n",
    "    }\n",
    "\n",
    "signature_def = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    ")\n",
    "\n",
    "model_builder.add_meta_graph_and_variables(\n",
    "    session,\n",
    "    tags=[tf.saved_model.tag_constants.SERVING],\n",
    "    signature_def_map={\n",
    "        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature_def\n",
    "    }\n",
    ")\n",
    "\n",
    "model_builder.save()\n",
    "\n",
    "print('model saved to models/tf_exported_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:17.804869Z",
     "start_time": "2018-10-24T05:16:17.800151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalars saved\n"
     ]
    }
   ],
   "source": [
    "# save the scaler\n",
    "yscalerfile = './models/yscaler.dat'\n",
    "pickle.dump(Y_scaler, open(yscalerfile, 'wb'))\n",
    "xscalerfile = './models/xscaler.dat'\n",
    "pickle.dump(X_scaler, open(xscalerfile, 'wb'))\n",
    "\n",
    "print('scalars saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:17.811150Z",
     "start_time": "2018-10-24T05:16:17.807764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.5   1.    1.    1.    0.    1.    0.    1.   59.99]\n"
     ]
    }
   ],
   "source": [
    "print(X_testing[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:17.817226Z",
     "start_time": "2018-10-24T05:16:17.813515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 1.  1.  1.  0.  1.  0.  1.  1. ]\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled_testing[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:17.841074Z",
     "start_time": "2018-10-24T05:16:17.819481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predict scaled earnings of Game #1 were 0.7850745320320129\n",
      "The actual earnings of Game #1 were $247537.0\n",
      "Our neural network predicted earnings of $243721.59375\n"
     ]
    }
   ],
   "source": [
    "# Now that the neural network is trained, let's use it to make predictions for our test data.\n",
    "# Pass in the X testing data and run the \"prediciton\" operation\n",
    "Y_predicted_scaled = session.run(prediction, feed_dict={X: X_scaled_testing})\n",
    "\n",
    "# Unscale the data back to it's original units (dollars)\n",
    "Y_predicted = Y_scaler.inverse_transform(Y_predicted_scaled)\n",
    "predicted_earnings = Y_predicted[0][0]\n",
    "\n",
    "real_earnings = test_data_df['total_earnings'].values[0]\n",
    "\n",
    "print(\"The predict scaled earnings of Game #1 were {}\".format(Y_predicted_scaled[0][0]))\n",
    "print(\"The actual earnings of Game #1 were ${}\".format(real_earnings))\n",
    "print(\"Our neural network predicted earnings of ${}\".format(predicted_earnings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:24.840889Z",
     "start_time": "2018-10-24T05:16:17.843497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['input'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 9)\r\n",
      "        name: input/Placeholder:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['earnings'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 1)\r\n",
      "        name: output/add:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "# Check the model signature with saved_model_cli\n",
    "\n",
    "!saved_model_cli show --dir ./models/tf_exported_model  --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:31.612359Z",
     "start_time": "2018-10-24T05:16:24.845385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]]\n",
      "The predict scaled earnings of Game #1 were 0.78507453\n"
     ]
    }
   ],
   "source": [
    "# Test prediction with saved_model_cli\n",
    "input = [[0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]]\n",
    "print(input)\n",
    "\n",
    "output = !saved_model_cli run --dir ./models/tf_exported_model --tag_set serve --signature_def serving_default --input_exprs 'input={ input }'\n",
    "\n",
    "scaledPrediction = eval(output[1])[0][0]\n",
    "\n",
    "print(\"The predict scaled earnings of Game #1 were {}\".format(scaledPrediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:31.621522Z",
     "start_time": "2018-10-24T05:16:31.615956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our neural network predicted earnings of $243721.58573765002\n"
     ]
    }
   ],
   "source": [
    "yscalerfile = './models/yscaler.dat'\n",
    "yscaler = pickle.load(open(yscalerfile, 'rb'))\n",
    "test_scaled_set = yscaler.inverse_transform(eval(output[1]))\n",
    "\n",
    "print(\"Our neural network predicted earnings of ${}\".format(test_scaled_set[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:16:31.627896Z",
     "start_time": "2018-10-24T05:16:31.623678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[243721.58573765]\n"
     ]
    }
   ],
   "source": [
    "# Manual calculation\n",
    "print((eval(output[1])[0]-Y_scaler.min_[0])/Y_scaler.scale_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-24T05:17:23.763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/bin/tensorboard\", line 7, in <module>\r\n",
      "    from tensorboard.main import run_main\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorboard/main.py\", line 39, in <module>\r\n",
      "    from tensorboard import default\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorboard/default.py\", line 34, in <module>\r\n",
      "    import tensorflow as tf\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/__init__.py\", line 22, in <module>\r\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/__init__.py\", line 81, in <module>\r\n",
      "    from tensorflow.python import keras\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/__init__.py\", line 30, in <module>\r\n",
      "    from tensorflow.python.keras import estimator\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/estimator/__init__.py\", line 28, in <module>\r\n",
      "    from tensorflow.python.estimator import keras as keras_lib  # pylint: disable=g-import-not-at-top\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/__init__.py\", line 25, in <module>\r\n",
      "    import tensorflow.python.estimator.estimator_lib\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator_lib.py\", line 41, in <module>\r\n",
      "    from tensorflow.python.estimator.inputs import inputs\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/inputs.py\", line 22, in <module>\r\n",
      "    from tensorflow.python.estimator.inputs.numpy_io import numpy_input_fn\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/numpy_io.py\", line 26, in <module>\r\n",
      "    from tensorflow.python.estimator.inputs.queues import feeding_functions\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py\", line 40, in <module>\r\n",
      "    import pandas as pd\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/__init__.py\", line 42, in <module>\r\n",
      "    from pandas.core.api import *\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/api.py\", line 10, in <module>\r\n",
      "    from pandas.core.groupby.groupby import Grouper\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/groupby/__init__.py\", line 2, in <module>\r\n",
      "    from pandas.core.groupby.groupby import (\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\", line 46, in <module>\r\n",
      "    from pandas.core.index import (Index, MultiIndex,\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/index.py\", line 2, in <module>\r\n",
      "    from pandas.core.indexes.api import *\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexes/api.py\", line 11, in <module>\r\n",
      "    from pandas.core.indexes.interval import IntervalIndex  # noqa\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 779, in get_code\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 487, in _compile_bytecode\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "# Visualize the log\n",
    "\n",
    "\n",
    "# Note: Stop once done\n",
    "!tensorboard --logdir=$LOGDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
